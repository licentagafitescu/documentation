\chapter{Detalii de implementare}
\section{Implementarea aplicației}

Implementarea aplicației a fost realizată într-un mod care permite următoarele acțiuni în cadrul unui scenariu de utilizare uzual:
\begin{enumerate}
    \item Modulul \textit{front-end} afișează pagina de autentificare și redirectează utilizatorul la procesul de autentificare de pe \textit{back-end} (Home Component)
    \item Modulul \textit{back-end} trimite cererea de autentificare prin OAuth la API-ul Flickr
    \item  Se salvează \textit{request token}-ului și redirectarea la autorizarea pagina de autentificare în Flickr și autorizare prin API-ul Flickr
    \item Se trimite \textit{request token}-ul autorizat de către utilizator pentru a obține un \textit{token} de acces
    \item  Se generează un identificator unic pentru utilizator, se salvează în baza de date împreună cu \textit{token}-ul de acces primit și apoi se face redirectarea către \textit{front-end} trimițând și identificatorul unic
    \item Modulul \textit{front-end} reține identificatorul utilizatorului și cere  datele despre profil 
    \item Modulul \textit{back-end} furnizează datele despre profil(nume utilizator, imagine de profil)
    \item \textit{Front-end}-ul redirectează utilizatorul la pagina de încărcare imagini (Login Component)
    \item Aici i se oferă utilizatorului posibilitatea de a încărca o imagine și de a alege sursa imaginilor, apoi trimite la modulul \textit{back-end} aceste informații (Image Upload Component)
    \item Modulul \textit{back-end} primește imaginea și opțiunile privitoare la sursă și  analizează imaginea cu o rețea neurală, obținând o listă de etichete
    \item Se apelează API-ul DataMuse pentru a obține cuvinte similare etichetelor obținute
    \item Se apelează API-ul Flickr pentru a obține imagini și acestea se  analizează cu rețeaua neurală
    \item Se compară etichetele imaginilor cu etichetele imaginii încărcate și se creează o listă de imagini similare
    \item Se returnează lista către \textit{front-end}
    \item \textit{Front-end}-ul afișează imaginile returnate de \textit{back-end} (Image Upload Component)
\end{enumerate}{}

\section{Detaliile modulului front-end}
Modulul \textit{front-end} este realizat cu ajutorul \textit{framework}-ului Angular. Angular este un \textit{framework} cu sursă deschisă dezvoltat de către Google pentru crearea de aplicații client  SPA (\textit{single-page application}) folosind HTML, CSS și TypeScript. O aplicație Angular este compusă din module, componente și servicii.


Este împărțit în 3 componente: \textit{HomeComponent}, \textit{LoginComponent} și \textit{ImageUploadComponent} și folosește 3 servicii: \textit{AuthService}, \textit{Auth-GuardService} și \textit{ImageService}.

\subsection{HomeComponent}
 Se află pe ruta /home și este prima componentă cu care interacționează orice utilizatorul. Rolul ei este de a oferi informații despre aplicație și a facilita procesul de autentificare. Are un singur buton, cel de "Login", care atunci când este apăsat va redirecta utilizatorul spre modulul de \textit{back-end} pentru continuarea procesului de autentificare.
 
 \subsection{LoginComponent}
 Această componentă are ruta /login/:id, unde parametrul id va reprezenta identificatorul utilizatorului trimis de către serviciul de \textit{back-end} prin redirectare. În cadrul componentei se va prelua valoarea parametrului din rută și se va apela funcția login din cadrul serviciului \textit{AuthService}. Această funcție se ocupă de salvarea identificatorului. Inițial acesta era salvat în LocalStorage, dar din considerente de securitate, s-a ales ca soluție SessionStorage, care se golește la părăsirea sesiunii curente. Componenta apelează din nou \textit{AuthService} și pentru a cere modulului de \textit{back-end} informații despre profilul de Flickr ale utilizatorului, informații salvate în cadrul serviciului. După aceste acțiuni, se folosește routerul din Angular pentru a redirecta utilizatorul către următoarea componentă, \textit{ImageUploadComponent}.
 
 \subsection{ImageUploadComponent}
Componenta aferentă rutei /upload, care este o rută protejată prin o gardă de rută. Gărzile de rută în Angular sunt interfețe care îi spun routerului dacă poate sau nu naviga la o anumită rută. Routerul decide în funcție de o valoare booleană returnată de o clasă care implementează interfața gărzii. În cadrul aplicației s-a folosit garda CanActivate, a cărei interfață a fost implementată de serviciul Auth-GuardService. Acesta conține o metodă care returnează valoarea adevărat pentru când utilizatorul este autentificat ( se determină cu ajutorul metodei isAuthenticated din cadrul AuthService, care caută dacă este salvat vreun identificator în SessionStorage) și fals pentru cazul în care nu este autentificat. Astfel ImageUploadComponent este accesibilă doar unui utilizator autentificat.

Componenta conține un buton "Choose Files" care odată apăsat deschide o fereastră de unde utilizatorul va alege o imagine, butonul având în spate un \textit{input} HTML de tip imagine. După ce utilizatorul selectează o imagine, se va apela funcția \textit{preview}, care va citi conținutul imaginii și o va afișa pe ecran, pentru ca utilizatorul să își vizualizeze selecția.În cadrul paginii există și un grup de 3 \textit{radio-buttons}, care permit utilizatorului să selecteze de unde vrea să provină imaginile care vor fi analizate pentru a determina similaritatea. Opțiunile sunt profilul de Flickr utilizatorului, imaginile utilizatorilor din lista sa de contacte sau imaginile publice de pe Flickr, în mod implicit fiind selectată opțiunea corespunzătoare propriului profil.

Apăsarea butonului de "Upload" va apela funcția cu același nume. Funcția va afișa un element de tip \textit{spinner} pe ecran pentru a indica utilizatorului procesarea cererii. De asemenea va prelua identificatorul cu ajutorul funcției getUser din AuthService, funcție ce preia identificatorul din SessionStorage. Componenta va apela funcția postImage din serviciul ImageService, folosind imaginea în format base64,  identificatorul utilizatorului și opțiunea acestuia ca parametri.

Folosind clientul de http din Angular, ImageService transmite o cerere la \textit{back-end} și returnează răspunsul acestuia. În funcție de răspuns, componenta va afișa lista de etichete aferente imaginii și imaginile similare vizual, sau un mesaj explicativ în cazul în care nu au fost găsite etichete/imagini.

\section{Detaliile modulului back-end}
Modulul de back-end este realizat cu ajutorul \textit{framework}-ului Flask în limbajul Python. Flask este un \textit{microframework} WSGI(\textit{Web Server Gateway Interface}) pentru realizarea de aplicații web, scris în Python. Este cunoscut pentru simplitatea sa, dar și pentru posibilitatea de a se scala pentru aplicații oricât de complexe.


\subsection{Autentificarea cu OAuth}
Pentru a realiza autentificarea pe platforma Flickr prin protocolul OAuth, aplicația folosește o bibliotecă de cod numită \textit{AuthLib} ce furnizează un client OAuth pentru Flask. Clientul este înregistrat în aplicație folosind anumite configurări (id-ul clientului, url-ul pentru autorizare, etc.) dintr-un fișier de configurări. Atunci când este accesată ruta /login, aplicația primește prin intermediul clientului OAuth un \textit{request token} și generează un identificator unic pentru utilizatorul ce a accesat ruta, salvând \textit{token}-ul într-un sistem de cache, apoi redirectează către ruta /authorize.

În cadrul funcției ce gestioneaza ruta /authorize, clientul OAuth schimbă \textit{request token}-ul, cu un \textit{token} OAuth de acces, pe care aplicația îl va salva împreună cu identificatorul generat într-o bază de date, apoi utilizatorul va fi redirectat la modulul de \textit{front-end}.

\subsection{Informații despre profil}
Aplicația va face o cerere la una din metodele disponibile prin API-ul Flickr, va împacheta informațiile cerute(nume utilizator și imagine de profil) într-un JSON și le va returna.

\subsection{Analiza unei imagini}
Pentru analiza unei imagini se folosește un model de rețea neurală disponibil prin biblioteca Keras. Numit \textit{NASNEtMobile} acest model este alcătuit din mai multe straturi convoluționale, fiind o versiune scalată a arhitecturii \textit{NASNet}, versiune optimizată pentru viteză crescută. Modelul este preantrenat pe setul de date ImageNet, putând clasifica imagini în 1000 categorii.
Biblioteca Keras oferă mai multe modele de rețele neurale preantrenate pe același set de date, figura ~\ref{fig:networks} conținând specificațiile lor.

\begin{figure}[!htbp]
    \begin{center}
        \includegraphics[width=0.8\textwidth]{images/neuralnetworks.png}
        \caption{Modelele de rețele disponibile prin Keras\label{fig:networks}}
    \end{center}
\end{figure}

Pentru a alege un anume model, s-au testat mai multe din cele disponibile, apoi s-a încercat a se face un compromis între acuratețe și viteza de analiză a unei imagini (cunoscută ca și viteza de \textit{forward-pass} în rețea). Ambii parametri depind de mărimea modelului, numărul de parametri, tipul de straturi folosite, precum și arhitectura modelului în general.

De asemenea viteza depinde și de mărimea imaginii analizate(aceeași indiferent de model) și mărimea la care trebuie dimensionată imaginea pentru a fi acceptată de model(diferită). În tabela \ref{table:1} se găsesc comparații ale modelelor încercate ținând cont de viteza medie de analiza a unei imagini (prima imagine după instanțierea modelului durează mai mult și nu a fost luată în considerare pentru medie), acuratețea modelului și mărimea datelor de intrare acceptate( în format (lățime, înălțime) ).


\begin{table}[ht!]
\centering
 \begin{tabular}{||c c c c c||} 
 \hline
 Model & Viteză medie & Acuratețe top-1 & Acuratețe top-5 & Format \\ [0.5ex] 
 \hline\hline
 NASNetMobile & 0.25 secunde & 0.7444 & 0.919 &(224,224) \\ 
 \hline
 ResNet50 & 0.6 secunde & 0.749 & 0.921 & (224,224) \\
 \hline
 MobileNetV2 & 0.25 secunde & 0.713 & 0.901 & (224,224) \\
 \hline
 VGG16 & 0.5 secunde & 0.713 & 0.901 & (224,224)  \\
 \hline
 InceptionResNetV2 & 1.23 secunde & 788 & 6344 &  (299,299) \\ [1ex] 
 \hline
\end{tabular}
\caption{Comparație între modelele încercate}
\label{table:1}
\end{table}

Fiecare model acceptă propriul tip de date de intrare, din acest motiv trebuie folosite funcțiile de preprocesare corespunzătoare, disponibile împreună cu modelul în biblioteca Keras. Modelul returnează o listă de predicții ce trebuie interpretată folosind din nou o funcție specifică modelului. După aceasta se obține  o listă de tuple, primul element din tuplă fiind o eticheta ce  descrie imaginea, iar al doilea fiind probabilitatea etichetei de a descrie corect imaginea.

Instanțierea modelului, preprocesarea imaginii și obținerea predicțiilor se realizează în modul următor:

 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}

\begin{lstlisting}[language=Python]
# obtinerea modelului preantrenat
model = NASNetMobile(weights="imagenet")
# decodarea imaginii din base64
image_response = base64.b64decode(image_response)
# citirea continutului imaginii
img = image.load_img(BytesIO(image_response), target_size=(224, 224))
# procesarea imaginii in numpy
img = image.img_to_array(img)
img = np.expand_dims(img, axis=0)
# preprocesarea conform specificatiilor modelului
img = preprocess_input(img)
# obtinerea predictiilor
predictions = model.predict(img)
#decodificarea predictiilor
predictions = decode_predictions(predictions)[0]
\end{lstlisting}

În funcție de cerințe, aplicația folosește și un parametru care precizează probabilitatea minimă acceptată pentru o etichetă ca aceasta să se regăsească în lista de etichete finală, acest parametru având momentan valoarea de 0.25.

\subsection{Preluarea imaginilor de pe Flickr}
În funcție de opțiunea aleasă pentru sursa imaginilor ce vor fi analizate, API-ul de la Flickr va fi folosit în mod diferit.

Totuși orice metodă este folosită, va fi preluată o listă de fotografii cu un format specific, un exemplu fiind:
\begin{lstlisting}[language=XML]
<photos page="2" pages="89" perpage="10" total="881">
	<photo id="2636" owner="47058503995@N01" 
		secret="a123456" server="2" title="test_04"
		ispublic="1" isfriend="0" isfamily="0" />
	<photo id="2635" owner="47058503995@N01"
		secret="b123456" server="2" title="test_03"
		ispublic="0" isfriend="1" isfamily="1" />
	<photo id="2633" owner="47058503995@N01"
		secret="c123456" server="2" title="test_01"
		ispublic="1" isfriend="0" isfamily="0" />
	<photo id="2610" owner="12037949754@N01"
		secret="d123456" server="2" title="00_tall"
		ispublic="1" isfriend="0" isfamily="0" />
</photos>
\end{lstlisting}
\cite{flickr-api}

\subsubsection{Folosirea metodei getPhotos}
Endpoint-ul flickr.people.getPhotos returnează imaginile de pe profilul unui anumit utilizator. Pentru a utiliza metoda, cererea trebuie să fie autentificată folosind \textit{token}-ul de acces. Metoda returnează imaginile vizibile utilizatorului autentificat. Aplicația folosește această metodă pentru a prelua imaginile de pe profilul utilizatorului, utilizând valoarea "user\_id=me" ca și parametru în cerere. 

\subsubsection{Folosirea metodei search}
În cazul opțiunii de a prelua imaginile de pe profilele contactelor, găsirea listei de contacte a utilizatorului și folosirea metodei getPhotos descrise anterior ar afecta negativ performanța aplicației, o cerere putând să aducă mii de fotografii și crescând în mod neacceptat viteza de răspuns.
Pentru a optimiza acest proces și pentru a prekua și imagini publice relevante de pe platformă, aplicația va folosi endpoint-ul flickr.photos.search, care returnează o listă de imagini ce corespund unor anumite criterii.

Pentru aducerea fotografiilor relevante din lista de contacte, se va folosi "contacts=1" ca și parametru în cerere. Tot ca și parametru se va folosi "text", adăugându-i ca valoare eticheta după care vrem să căutăm imagini. Căutarea se va face în descriere, titlu și etichetele imaginilor, așa cum s-a menționat anterior. Pentru a primi cele mai relevante imagini, cererea va include și parametrul "sort=relevance".

Transformarea unei imagini din formatul returnat de cele două metode într-un url se face folosind o funcție din aplicație ce construiește url-ul folosind informațiile primite, url construit după un format prestabilit.
\begin{lstlisting}[language=Python]
data["farm-id"] = photo.get("farm", "")
data["server-id"] = photo.get("server")
data["id"] = photo.get("id")
data["secret"] = photo.get("secret")
photo_url = "https://farm{farm-id}.staticflickr.com/{server-id}/{id}_{secret}.jpg".format(**data)
\end{lstlisting}

\subsection{Optimizarea procesului de returnare a imaginilor}
Pentru a optimiza procesul de returnare a imaginilor, atât din punct de vedere al similarității vizuale, cât și a timpului de răspuns, folosim două procedee:
\subsubsection{API-ul DataMuse}
API-ul DataMuse permite căutarea unor sinonime, cuvinte înrudite sau cuvinte ce respectă anumite reguli în raport cu un cuvânt dat. Deoarece, de exemplu, e de dorit ca și imaginile etichetate "castel" și cele etichetate "palat" să fie returnate, deoarece au similaritate vizuală mare, se folosește API-ul pentru a căuta cuvinte cu înțeles similar cu etichetele. Pentru fiecare etichetă, se vor lua primele 3 cuvinte similare(dacă există) cu eticheta și se vor introduce în lista de etichete a imaginii. Astfel se optimizează performanța aplicației, detectându-se mai multe imagini similare din punct de vedere vizual.
\subsubsection{Sistem de cache}
Deoarece analiza unei singure imagini durează în medie 0.25 secunde, întreg procesul, ce include aducerea imaginilor, deschiderea fiecărui url și preluarea imaginii, analizarea ei, folosirea API-ului WordMuse și detectarea similarității ajunge să dureze în medie 60-70 de secunde pentru o cerere în care se analizează 100 de imagini, timpul crescând în mod evident o dată cu creșterea numărului de imagini. Soluția pentru a optimiza acest proces este folosirea unui sistem de cache, astfel încât cererile consecutive cu imagini etichetate identic de către rețea se vor rezolva mult mai repede, fiind necesar doar timpul de analiză al imaginii inițiale și accesarea sistemului de cache.